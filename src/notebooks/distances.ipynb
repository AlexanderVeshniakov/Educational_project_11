{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Открой файл [distances.ipynb](src/notebooks/distances.ipynb). \n",
    "* Объедини общие данные о фильмах [tmdb_5000_movies](https://files.sberdisk.ru/s/te4QbzdxKgsFQXA) и каст фильмов \n",
    "[tmdb_5000_credits](https://files.sberdisk.ru/s/H9oRuXQt5mFz3T9). \n",
    "* Оставь в датасете только фильмы, которые вышли в \"релиз\".\n",
    "* Убери фильмы с пропусками в колонках ['overview', 'genres', 'keywords']\n",
    "* Выведи количество фильмов, оставшихся в выборке "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_movies():\n",
    "    movie_df = pd.read_csv('../datasets/tmdb_5000_movies.csv')\n",
    "    credits_df = pd.read_csv('../datasets/tmdb_5000_credits.csv')\n",
    "    credits_df.drop('title', inplace=True, axis=1)\n",
    "    df = pd.merge(movie_df, credits_df, left_on='id', right_on='movie_id')\n",
    "    df = df[df.status == 'Released']\n",
    "    df.dropna(subset=['overview', 'genres', 'keywords'], inplace=True)\n",
    "    df.loc[:, ['overview', 'genres', 'keywords']] = df[['overview', 'genres', 'keywords']].fillna('')\n",
    "    return df\n",
    "    \n",
    "df_movies = filter_movies()\n",
    "print(\"Количество оставшихся фильмов:\", len(df_movies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем алгоритм рекомендации на основе описания фильма (`overview`) и ключевых слов к фильму (`keywords`). \n",
    "Объедини тексты этих колонок и проведи предобработку:\n",
    "* Замени NaN в описании фильма на пустой символ `''`\n",
    "* Удали все английские стоп-слова (используй параметр `stop_words` в `TfidfVectorizer`)\n",
    "* Рассчитай матрицу [Tf-Idf](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) для описания фильмов.\n",
    "\n",
    "Выведи размер получившейся матрицы\n",
    "> Параметр `max_features` в `TfidfVectorizer` должен быть равен 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tf_matrix(data):\n",
    "    data['text'] = data['overview'] + ' ' + data['keywords']\n",
    "    tf = TfidfVectorizer(stop_words='english', max_features=10000)\n",
    "    tfidf_matrix = tf.fit_transform(data['text'])\n",
    "    \n",
    "    return tfidf_matrix\n",
    "\n",
    "matrix = calculate_tf_matrix(df_movies)\n",
    "print(\"Размер матрицы Tf-Idf:\", matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитай [cosine similarity](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html) \n",
    "между фильмами. Составь из этой матрицы `pd.DataFrame`. Для дальнейшего удобства, \n",
    "колонки и индексы таблицы назови согласно`id` фильма. \\\n",
    "Сохрани получившийся `DataFrame` c расстояниями в папку [assets](src/assets) с названием `distance.csv`.\n",
    "А сам объединенный датасет с фильмами сохрани в папку [assets](src/assets) с названием `movies.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(matrix, df_movies, assets_folder):\n",
    "    # Рассчитываем cosine similarity\n",
    "    cosine_sim = cosine_similarity(matrix, matrix)\n",
    "    df_cosine_sim = pd.DataFrame(cosine_sim, columns=df_movies['movie_id'], index=df_movies['movie_id'])\n",
    "    \n",
    "    # Проверяем наличие файла distance.csv\n",
    "    distance_filepath = os.path.join(assets_folder, 'distance.csv')\n",
    "    if not os.path.exists(distance_filepath):\n",
    "        # Сохраняем DataFrame с расстояниями в CSV-файл\n",
    "        df_cosine_sim.to_csv(distance_filepath)\n",
    "    else:\n",
    "        # Перезаписываем файл, если он уже существует\n",
    "        df_cosine_sim.to_csv(distance_filepath, index=True)\n",
    "\n",
    "    # Проверяем наличие файла movies.csv\n",
    "    movies_filepath = os.path.join(assets_folder, 'movies.csv')\n",
    "    if not os.path.exists(movies_filepath):\n",
    "        # Сохраняем объединенный датасет с фильмами в CSV-файл\n",
    "        df_movies.to_csv(movies_filepath, index=True)\n",
    "    else:\n",
    "        # Перезаписываем файл, если он уже существует\n",
    "        df_movies.to_csv(movies_filepath, index=True)\n",
    "\n",
    "\n",
    "assets_folder = '../src/assets'\n",
    "calculate_cosine_similarity(matrix, df_movies, assets_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
